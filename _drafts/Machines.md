---
layout: post
title: ""
date: 2020-02-14
description:
tags:
- Systems Engineering
- modelling
- Functional architecture
- SysML
comments: true
---

I've noticed something strange about the way I talk to voice assistants, perhaps you've noticed it too? Instead of the way I'd politely ask my girlfriend:
> "Pop the light on, would you?"

I end up saying:
> "Turn living room light on."

This usually involves the same tone of voice used to speak to a hard of hearing person on the third repeat. Of course, the silicon valley lot are feeding countless recorded conversations into their machine learning algorithms to improve their capability of understanding -eavesdropped conversations for advertising purposes- normal speech patterns to make interacting with these as assistants as close to human interaction as possible.

This got me thinking, what if the tech giants didn't have an ulterior motive for understanding the nuances of natural speech? We're all relatively happy now talking to our living room lights as if they're half deaf, so would we worry? @@

There is a tendency in the engineering community to try to simplify the problem. I don't mean the "divide and conquer" method where we cut the complex problem up into solvable pieces, I'm talking about the simplification of the problem into one that is more easily solved and solve that one instead. Complexity gets swept under the carpet. Products are built so that only right-handed men can safely operate them despite 10% of the population being left handed and just over 50% being women. Probably the main contributor to this tendency is the lack of diversity in engineering meaning that problems of @@

Our tendency to meet the machine halfway can be harmful though, especially when the limitations of the technology disappear but we "get used" to the leakiness of the abstraction. A good example of where this has become apparent is in modern farming.
